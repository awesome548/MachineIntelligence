{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "input_size = 6\n",
    "train_size = 450\n",
    "test_size = 100\n",
    "test_minisize = 50\n",
    "output_size = 2\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 70\n",
    "epoch_num = 200\n",
    "batch = 16\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./Dataset/myData/Kikuzo0701.csv\")\n",
    "f_o = open(\"./Dataset/myData/kikuzo0701_out.csv\", \"w\")\n",
    "\n",
    "line = f.readline()\n",
    "while line:\n",
    "    f_o.writelines([line[:-7], \"\\n\"])\n",
    "    line = f.readline()\n",
    "\n",
    "f.close()\n",
    "f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58634, 6)\n",
      "(65271, 6)\n",
      "(65246, 6)\n",
      "(509, 128, 6)\n",
      "(458, 128, 6)\n",
      "(509, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/myData/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "amaya_data = np.loadtxt(path + \"amaya0701_out.csv\", delimiter=\",\", skiprows=100)\n",
    "kikuzo_data = np.loadtxt(path + \"kikuzo0701_out.csv\", delimiter=\",\", skiprows=100)\n",
    "rinto_data = np.loadtxt(path + \"rinto0701_out.csv\", delimiter=\",\", skiprows=100)\n",
    "\n",
    "amaya_data = amaya_data[:,1:7]\n",
    "kikuzo_data = kikuzo_data[:,1:7]\n",
    "rinto_data = rinto_data[:,1:7]\n",
    "print(amaya_data.shape)\n",
    "print(kikuzo_data.shape)\n",
    "print(rinto_data.shape)\n",
    "\n",
    "# train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "# train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "# #test set\n",
    "# test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "# test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "# test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "# test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "# test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "kikuzo = np.ones((int(len(kikuzo_data)/seq_len), seq_len, input_size), float)\n",
    "amaya = np.ones((int(len(amaya_data)/seq_len), seq_len, input_size), float)\n",
    "rinto = np.ones((int(len(rinto_data)/seq_len), seq_len, input_size), float)\n",
    "\n",
    "for i in range(int(len(kikuzo_data)/seq_len)):\n",
    "    kikuzo[i,:,:] = kikuzo_data[i*seq_len:(i+1)*seq_len,:]\n",
    "for i in range(int(len(amaya_data)/seq_len)):\n",
    "    amaya[i,:,:] = amaya_data[i*seq_len:(i+1)*seq_len,:]\n",
    "for i in range(int(len(rinto_data)/seq_len)):\n",
    "    rinto[i,:,:] = rinto_data[i*seq_len:(i+1)*seq_len,:]\n",
    "    \n",
    "print(kikuzo.shape)\n",
    "print(amaya.shape)\n",
    "print(rinto.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 128, 6)\n",
      "(100, 128, 6)\n",
      "(450,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "trX = rinto[:train_size]\n",
    "print(trX.shape)\n",
    "#amaya_test = amaya[:50]\n",
    "rinto_test = rinto[450:500]\n",
    "kikuzo_test = kikuzo[:50]\n",
    "\n",
    "teX = np.vstack([rinto_test, kikuzo_test])\n",
    "print(teX.shape)\n",
    "\n",
    "trY = np.zeros(train_size, int)\n",
    "print(trY.shape)\n",
    "\n",
    "teY = np.zeros(test_size, int)\n",
    "teY[50:100] = np.ones(50,int)\n",
    "#teY[100:150] = np.ones(50, int) + 1\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape:torch.Size([450, 128, 6])\n",
      "trainY.shape:torch.Size([450])\n",
      "testX.shape:torch.Size([100, 128, 6])\n",
      "testY.shape:torch.Size([100])\n",
      "trainY.shape:torch.Size([450, 2])\n",
      "testY: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "print('trainX.shape:{0}'.format(trainX.shape))\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "print('testX.shape:{0}'.format(testX.shape))\n",
    "print('testY.shape:{0}'.format(testY.shape))\n",
    "\n",
    "# trainYをone-hotにするためlongにsuru\n",
    "trainY = trainY.long()\n",
    "# one-hotにする \n",
    "trainY = F.one_hot(trainY, num_classes=output_size)\n",
    "# 誤差を計算できるようにfloatに直す\n",
    "trainY = trainY.float()\n",
    "# trY one-hotにする\n",
    "trY = trainY.cpu().data.numpy()\n",
    "\n",
    "#testY one-hot ni sinai!\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "\n",
    "print('testY: {0}'.format(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.lstm_1 = nn.LSTM(input_size=6, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, \\\n",
    "                              num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.hidden_size_2, output_size)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  model = model.to(device)\n",
    "  for epoch in range(epoch_num):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=learning_rate)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=output_size)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=output_size)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 0.52868\n",
      "Epoch = 21, Loss = 0.01955\n",
      "Epoch = 41, Loss = 0.00704\n",
      "Epoch = 61, Loss = 0.00483\n",
      "Epoch = 81, Loss = 0.00288\n",
      "Epoch = 101, Loss = 0.00206\n",
      "Epoch = 121, Loss = 0.00197\n",
      "Epoch = 141, Loss = 0.00162\n",
      "Epoch = 161, Loss = 0.00157\n",
      "Epoch = 181, Loss = 0.00110\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 2])\n",
      "tensor([[50,  0],\n",
      "        [50,  0]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop = len(loss)\n",
    "step = int(len(loss) / epoch_num)\n",
    "plt.plot(loss[0:stop:step], '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f1979eed7bd90e93f7098e88a58aab24ec26102a23b5ea93df2879eff80801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
