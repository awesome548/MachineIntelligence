{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person = 1 # 0 = kikuzo, 1 = amaya, 2 = rinto\n",
    "subject_num = 8\n",
    "test_num = 2\n",
    "seq_len = 128\n",
    "input_size = 6\n",
    "train_size = 350\n",
    "test_size = 100\n",
    "test_minisize = 50\n",
    "output_size = 2\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 70\n",
    "epoch_num = 200\n",
    "batch = 16\n",
    "learning_rate = 0.01\n",
    "path = \"./Dataset/myData/\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 5 6 7] [0 3]\n"
     ]
    }
   ],
   "source": [
    "temp = np.arange(subject_num)\n",
    "temp = np.delete(temp,train_person)\n",
    "np.random.shuffle(temp)\n",
    "train_subject = temp[test_num:]\n",
    "test_subject = temp[0:test_num]\n",
    "train_subject.sort()\n",
    "test_subject.sort()\n",
    "print(train_subject, test_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(subject_num):\n",
    "    f = open(path + \"person_\" + str(i) + \".csv\")\n",
    "    f_o = open(path + \"person_\" + str(i) + \"_out.csv\", \"w\")\n",
    "\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        f_o.writelines([line[:-7], \"\\n\"])\n",
    "        line = f.readline()\n",
    "\n",
    "    f.close()\n",
    "    f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 0 (509, 128, 6)\n",
      "data 1 (458, 128, 6)\n",
      "data 2 (509, 128, 6)\n",
      "data 3 (94, 128, 6)\n",
      "data 4 (145, 128, 6)\n",
      "data 5 (147, 128, 6)\n",
      "data 6 (121, 128, 6)\n",
      "data 7 (148, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "#scale data set\n",
    "data = []\n",
    "for i in range(subject_num):\n",
    "    load = np.loadtxt(path + \"person_\" + str(i) + \"_out.csv\", delimiter=\",\", skiprows=100)\n",
    "    load = load[:,1:7]\n",
    "\n",
    "    preData = np.zeros((int(len(load) / seq_len), seq_len, input_size), float)\n",
    "    for j in range(int(len(load) / seq_len)):\n",
    "        preData[j,:,:] = load[j * seq_len : (j + 1) * seq_len, :]\n",
    "    \n",
    "    data.append(preData)\n",
    "    print(\"data\", i, preData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 128, 6)\n",
      "(200, 128, 6)\n",
      "(700,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "#trainnig person : other = 1 : 1\n",
    "trX = data[train_person][:train_size]\n",
    "for i in train_subject:\n",
    "    trX = np.vstack([trX, data[i][:train_size//len(train_subject)]])\n",
    "\n",
    "trY = np.hstack([np.zeros(train_size, int), np.ones(train_size, int)])\n",
    "\n",
    "teX = data[train_person][train_size:train_size + test_size]\n",
    "for i in test_subject:\n",
    "    teX = np.vstack([teX, data[i][:test_size // len(test_subject)]])\n",
    "\n",
    "teY = np.hstack([np.zeros(test_size, int), np.ones(test_size, int)])\n",
    "\n",
    "print(trX.shape)\n",
    "print(teX.shape)\n",
    "print(trY.shape)\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape:torch.Size([700, 128, 6])\n",
      "trainY.shape:torch.Size([700])\n",
      "testX.shape:torch.Size([200, 128, 6])\n",
      "testY.shape:torch.Size([200])\n",
      "trainY.shape:torch.Size([700, 2])\n"
     ]
    }
   ],
   "source": [
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "print('trainX.shape:{0}'.format(trainX.shape))\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "print('testX.shape:{0}'.format(testX.shape))\n",
    "print('testY.shape:{0}'.format(testY.shape))\n",
    "\n",
    "# trainYをone-hotにするためlongにsuru\n",
    "trainY = trainY.long()\n",
    "# one-hotにする \n",
    "trainY = F.one_hot(trainY, num_classes=output_size)\n",
    "# 誤差を計算できるようにfloatに直す\n",
    "trainY = trainY.float()\n",
    "# trY one-hotにする\n",
    "trY = trainY.cpu().data.numpy()\n",
    "\n",
    "#testY one-hot ni sinai!\n",
    "print('trainY.shape:{0}'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.lstm_1 = nn.LSTM(input_size=6, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, \\\n",
    "                              num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.hidden_size_2, output_size)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  model = model.to(device)\n",
    "  for epoch in range(epoch_num):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=learning_rate)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=output_size)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=output_size)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 0.69644\n",
      "Epoch = 21, Loss = 0.13484\n",
      "Epoch = 41, Loss = 0.01989\n",
      "Epoch = 61, Loss = 0.00731\n",
      "Epoch = 81, Loss = 0.00435\n",
      "Epoch = 101, Loss = 0.00320\n",
      "Epoch = 121, Loss = 0.00262\n",
      "Epoch = 141, Loss = 0.00159\n",
      "Epoch = 161, Loss = 0.00138\n",
      "Epoch = 181, Loss = 0.00130\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2])\n",
      "torch.Size([200])\n",
      "torch.Size([200, 2])\n",
      "tensor([[100,   0],\n",
      "        [ 48,  52]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop = len(loss)\n",
    "step = int(len(loss) / epoch_num)\n",
    "plt.plot(loss[0:stop:step], '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
