{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person = 1 # 0 = kikuzo, 1 = amaya, 2 = rinto\n",
    "subject_num = 8\n",
    "test_num = 2\n",
    "seq_len = 128\n",
    "input_size = 6\n",
    "train_size = 350\n",
    "test_size = 100\n",
    "test_minisize = 50\n",
    "output_size = 2\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 70\n",
    "epoch_num = 200\n",
    "batch = 16\n",
    "learning_rate = 0.01\n",
    "path = \"./Dataset/myData/\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "\n",
    "temp = np.arange(subject_num)\n",
    "temp = np.delete(temp,train_person)\n",
    "np.random.shuffle(temp)\n",
    "train_subject = temp[test_num:]\n",
    "test_subject = temp[0:test_num]\n",
    "train_subject.sort()\n",
    "test_subject.sort()\n",
    "print(train_subject, test_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(subject_num):\n",
    "    f = open(path + \"person_\" + str(i) + \".csv\")\n",
    "    f_o = open(path + \"person_\" + str(i) + \"_out.csv\", \"w\")\n",
    "\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        f_o.writelines([line[:-7], \"\\n\"])\n",
    "        line = f.readline()\n",
    "\n",
    "    f.close()\n",
    "    f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data set\n",
    "data = []\n",
    "for i in range(subject_num):\n",
    "    load = np.loadtxt(path + \"person_\" + str(i) + \"_out.csv\", delimiter=\",\", skiprows=100)\n",
    "    load = load[:,1:7]\n",
    "\n",
    "    preData = np.zeros((int(len(load) / seq_len), seq_len, input_size), float)\n",
    "    for j in range(int(len(load) / seq_len)):\n",
    "        preData[j,:,:] = load[j * seq_len : (j + 1) * seq_len, :]\n",
    "    \n",
    "    data.append(preData)\n",
    "    print(\"data\", i, preData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainnig person : other = 1 : 1\n",
    "trX = data[train_person][:train_size]\n",
    "for i in train_subject:\n",
    "    trX = np.vstack([trX, data[i][:train_size//len(train_subject)]])\n",
    "\n",
    "trY = np.hstack([np.zeros(train_size, int), np.ones(train_size, int)])\n",
    "\n",
    "teX = data[train_person][train_size:train_size + test_size]\n",
    "for i in test_subject:\n",
    "    teX = np.vstack([teX, data[i][:test_size // len(test_subject)]])\n",
    "\n",
    "teY = np.hstack([np.zeros(test_size, int), np.ones(test_size, int)])\n",
    "\n",
    "print(trX.shape)\n",
    "print(teX.shape)\n",
    "print(trY.shape)\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "print('trainX.shape:{0}'.format(trainX.shape))\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "print('testX.shape:{0}'.format(testX.shape))\n",
    "print('testY.shape:{0}'.format(testY.shape))\n",
    "\n",
    "# trainYをone-hotにするためlongにsuru\n",
    "trainY = trainY.long()\n",
    "# one-hotにする \n",
    "trainY = F.one_hot(trainY, num_classes=output_size)\n",
    "# 誤差を計算できるようにfloatに直す\n",
    "trainY = trainY.float()\n",
    "# trY one-hotにする\n",
    "trY = trainY.cpu().data.numpy()\n",
    "\n",
    "#testY one-hot ni sinai!\n",
    "print('trainY.shape:{0}'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.lstm_1 = nn.LSTM(input_size=6, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, \\\n",
    "                              num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.hidden_size_2, output_size)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  model = model.to(device)\n",
    "  for epoch in range(epoch_num):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=learning_rate)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=output_size)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=output_size)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = len(loss)\n",
    "step = int(len(loss) / epoch_num)\n",
    "plt.plot(loss[0:stop:step], '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
