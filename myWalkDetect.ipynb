{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 6 7] [2 5]\n"
     ]
    }
   ],
   "source": [
    "train_person = 1 # 0 = kikuzo, 1 = amaya, 2 = rinto\n",
    "subject_num = 8\n",
    "test_num = 2\n",
    "seq_len = 128\n",
    "input_size = 6\n",
    "train_size = 350\n",
    "test_size = 100\n",
    "test_minisize = 50\n",
    "output_size = 2\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 70\n",
    "epoch_num = 200\n",
    "batch = 16\n",
    "learning_rate = 0.01\n",
    "path = \"./Dataset/myData/\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "\n",
    "temp = np.arange(subject_num)\n",
    "temp = np.delete(temp,train_person)\n",
    "np.random.shuffle(temp)\n",
    "train_subject = temp[test_num:]\n",
    "test_subject = temp[0:test_num]\n",
    "train_subject.sort()\n",
    "test_subject.sort()\n",
    "print(train_subject, test_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(subject_num):\n",
    "    f = open(path + \"person_\" + str(i) + \".csv\")\n",
    "    f_o = open(path + \"person_\" + str(i) + \"_out.csv\", \"w\")\n",
    "\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        f_o.writelines([line[:-7], \"\\n\"])\n",
    "        line = f.readline()\n",
    "\n",
    "    f.close()\n",
    "    f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 0 (509, 128, 6)\n",
      "data 1 (458, 128, 6)\n",
      "data 2 (509, 128, 6)\n",
      "data 3 (94, 128, 6)\n",
      "data 4 (145, 128, 6)\n",
      "data 5 (147, 128, 6)\n",
      "data 6 (121, 128, 6)\n",
      "data 7 (148, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "#scale data set\n",
    "data = []\n",
    "for i in range(subject_num):\n",
    "    load = np.loadtxt(path + \"person_\" + str(i) + \"_out.csv\", delimiter=\",\", skiprows=100)\n",
    "    load = load[:,1:7]\n",
    "\n",
    "    preData = np.zeros((int(len(load) / seq_len), seq_len, input_size), float)\n",
    "    for j in range(int(len(load) / seq_len)):\n",
    "        preData[j,:,:] = load[j * seq_len : (j + 1) * seq_len, :]\n",
    "    \n",
    "    data.append(preData)\n",
    "    print(\"data\", i, preData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 128, 6)\n",
      "(200, 128, 6)\n",
      "(700,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "#trainnig person : other = 1 : 1\n",
    "trX = data[train_person][:train_size]\n",
    "for i in train_subject:\n",
    "    trX = np.vstack([trX, data[i][:train_size//len(train_subject)]])\n",
    "\n",
    "trY = np.hstack([np.zeros(train_size, int), np.ones(train_size, int)])\n",
    "\n",
    "teX = data[train_person][train_size:train_size + test_size]\n",
    "for i in test_subject:\n",
    "    teX = np.vstack([teX, data[i][:test_size // len(test_subject)]])\n",
    "\n",
    "teY = np.hstack([np.zeros(test_size, int), np.ones(test_size, int)])\n",
    "\n",
    "print(trX.shape)\n",
    "print(teX.shape)\n",
    "print(trY.shape)\n",
    "print(teY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape:torch.Size([700, 128, 6])\n",
      "trainY.shape:torch.Size([700])\n",
      "testX.shape:torch.Size([200, 128, 6])\n",
      "testY.shape:torch.Size([200])\n",
      "trainY.shape:torch.Size([700, 2])\n"
     ]
    }
   ],
   "source": [
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "print('trainX.shape:{0}'.format(trainX.shape))\n",
    "print('trainY.shape:{0}'.format(trainY.shape))\n",
    "print('testX.shape:{0}'.format(testX.shape))\n",
    "print('testY.shape:{0}'.format(testY.shape))\n",
    "\n",
    "# trainYをone-hotにするためlongにsuru\n",
    "trainY = trainY.long()\n",
    "# one-hotにする \n",
    "trainY = F.one_hot(trainY, num_classes=output_size)\n",
    "# 誤差を計算できるようにfloatに直す\n",
    "trainY = trainY.float()\n",
    "# trY one-hotにする\n",
    "trY = trainY.cpu().data.numpy()\n",
    "\n",
    "#testY one-hot ni sinai!\n",
    "print('trainY.shape:{0}'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.lstm_1 = nn.LSTM(input_size=6, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, \\\n",
    "                              num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.hidden_size_2, output_size)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  model = model.to(device)\n",
    "  for epoch in range(epoch_num):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=learning_rate)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=output_size)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=output_size)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 0.69097\n",
      "Epoch = 21, Loss = 0.40884\n",
      "Epoch = 41, Loss = 0.06272\n",
      "Epoch = 61, Loss = 0.00994\n",
      "Epoch = 81, Loss = 0.00652\n",
      "Epoch = 101, Loss = 0.00375\n",
      "Epoch = 121, Loss = 0.00245\n",
      "Epoch = 141, Loss = 0.00256\n",
      "Epoch = 161, Loss = 0.00194\n",
      "Epoch = 181, Loss = 0.00146\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2])\n",
      "torch.Size([200])\n",
      "torch.Size([200, 2])\n",
      "tensor([[100,   0],\n",
      "        [  7,  93]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop = len(loss)\n",
    "step = int(len(loss) / epoch_num)\n",
    "plt.plot(loss[0:stop:step], '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
