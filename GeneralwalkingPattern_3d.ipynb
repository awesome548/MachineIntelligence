{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "train_ax = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_x_train.txt\"))\n",
    "train_ay = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_y_train.txt\"))\n",
    "train_az = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_z_train.txt\"))\n",
    "\n",
    "train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "#test set\n",
    "test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "print(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7352\n",
    "test_size = 2947\n",
    "dim_size = 3\n",
    "sample_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape initial:(7352, 128, 3)\n",
      "trX.shape assigned:(7352, 128, 3)\n",
      "teX.shape initial:(2947, 128, 3)\n",
      "trX.shape assigned:(2947, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# trX = (7352, 128, 3) ... trainのX\n",
    "trX = np.ones((train_size, sample_size, dim_size), float)\n",
    "print('trX.shape initial:{0}'.format(trX.shape))\n",
    "for i in range(train_size):\n",
    "  #temp1 = np.ones((dim_size, sample_size), float)\n",
    "  trX[i,:,0] = train_ax[i,:]\n",
    "  trX[i,:,1] = train_ay[i,:]\n",
    "  trX[i,:,2] = train_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(trX.shape))\n",
    "\n",
    "\n",
    "# t(movement label) or s(subject label) or both ... trainのY (7352,1)\n",
    "trY = train_t.reshape(-1,1)\n",
    "\n",
    "# teX = (2947, 3, 128) ... testのX\n",
    "teX = np.ones((test_size, sample_size, dim_size), float)\n",
    "print('teX.shape initial:{0}'.format(teX.shape))\n",
    "for i in range(test_size):\n",
    "  #temp2 = np.ones((dim_size, sample_size), float)\n",
    "  teX[i,:,0] = test_ax[i,:]\n",
    "  teX[i,:,1] = test_ay[i,:]\n",
    "  teX[i,:,2] = test_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(teX.shape))\n",
    "\n",
    "# testのY 2947行1列\n",
    "teY = test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_t[0], '.', label = \"train_ax\")\n",
    "plt.plot(trY[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datax.shape:(10299, 128, 3)\n",
      "datay.shape:(10299, 1)\n",
      "torch.Size([7352])\n",
      "tensor(0, device='cuda:0') tensor(5, device='cuda:0')\n",
      "torch.Size([7352, 6])\n",
      "tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "(7352, 6)\n"
     ]
    }
   ],
   "source": [
    "datax = np.vstack([trX, teX])\n",
    "print('datax.shape:{0}'.format(datax.shape))\n",
    "datay = np.vstack([trY, teY])\n",
    "print('datay.shape:{0}'.format(datay.shape))\n",
    "# dataX = trX and teX (10299, 3, 128)\n",
    "dataX = torch.Tensor(np.array(datax)).to(device)\n",
    "# dataY = trY and teY (10299,1)\n",
    "dataY = torch.Tensor(np.array(datay)).to(device)\n",
    "\n",
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "# trainYをone-hotにするためlongにして1次元配列に戻す　-> min~maxを0~5に直す\n",
    "trainY = trainY.view(-1).long() - 1\n",
    "print(trainY.shape)\n",
    "print(torch.min(trainY), torch.max(trainY))\n",
    "\n",
    "# one-hotにする -> 誤差を計算できるようにfloatに直す\n",
    "trainY = F.one_hot(trainY, num_classes=-1)\n",
    "trainY = trainY.float()\n",
    "print(trainY.shape)\n",
    "print(trainY)\n",
    "trY = trainY.cpu().data.numpy()\n",
    "print(trY.shape)\n",
    "#print(trainX)\n",
    "testY = testY.view(-1).long() - 1\n",
    "# testY = F.one_hot(testY, num_classes=-1)\n",
    "# testY = testY.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2947, 128, 3])\n",
      "tensor([4, 4, 4,  ..., 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全データ数: 7352\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet()\n",
    "print('全データ数:',len(dataset))\n",
    "# print('3番目のデータ:',dataset[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = 50\n",
    "        self.hidden_size_2 = 70\n",
    "        self.lstm_1 = nn.LSTM(input_size=3, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(70, 6)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "#print(summary(MyLSTM(), input_size=(7352, 128, 3), device=torch.device(device)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epoch in range(200):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 1.79035\n",
      "Epoch = 21, Loss = 1.26522\n",
      "Epoch = 41, Loss = 1.29571\n",
      "Epoch = 61, Loss = 1.32935\n",
      "Epoch = 81, Loss = 1.74953\n",
      "Epoch = 101, Loss = 1.01327\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=-1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=-1)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=6)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.view(-1).int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'walkDetectModel.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f1979eed7bd90e93f7098e88a58aab24ec26102a23b5ea93df2879eff80801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
