{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "train_ax = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_x_train.txt\"))\n",
    "train_ay = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_y_train.txt\"))\n",
    "train_az = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_z_train.txt\"))\n",
    "\n",
    "train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "#test set\n",
    "test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "print(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7352\n",
    "test_size = 2947\n",
    "dim_size = 3\n",
    "sample_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape initial:(7352, 128, 3)\n",
      "trX.shape assigned:(7352, 128, 3)\n",
      "teX.shape initial:(2947, 128, 3)\n",
      "trX.shape assigned:(2947, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# trX = (7352, 128, 3) ... trainのX\n",
    "trX = np.ones((train_size, sample_size, dim_size), float)\n",
    "print('trX.shape initial:{0}'.format(trX.shape))\n",
    "for i in range(train_size):\n",
    "  temp1 = np.ones((dim_size, sample_size), float)\n",
    "  temp1[0,:] = train_ax[i,:]\n",
    "  temp1[1,:] = train_ay[i,:]\n",
    "  temp1[2,:] = train_az[i,:]\n",
    "  trX[i,:,:] = temp1.reshape(-1,3)\n",
    "print('trX.shape assigned:{0}'.format(trX.shape))\n",
    "\n",
    "# t(movement label) or s(subject label) or both ... trainのY (7352,1)\n",
    "trY = train_t.reshape(-1,1)\n",
    "\n",
    "# teX = (2947, 3, 128) ... testのX\n",
    "teX = np.ones((test_size, sample_size, dim_size), float)\n",
    "print('teX.shape initial:{0}'.format(teX.shape))\n",
    "for i in range(test_size):\n",
    "  temp2 = np.ones((dim_size, sample_size), float)\n",
    "  temp2[0,:] = test_ax[i,:]\n",
    "  temp2[1,:] = test_ay[i,:]\n",
    "  temp2[2,:] = test_az[i,:]\n",
    "  teX[i,:,:] = temp2.reshape(-1,3)\n",
    "print('trX.shape assigned:{0}'.format(teX.shape))\n",
    "\n",
    "# testのY 2947行1列\n",
    "teY = test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datax.shape:(10299, 128, 3)\n",
      "datay.shape:(10299, 1)\n",
      "torch.Size([7352])\n",
      "tensor(0, device='cuda:0') tensor(5, device='cuda:0')\n",
      "torch.Size([7352, 6])\n",
      "tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "datax = np.vstack([trX, teX])\n",
    "print('datax.shape:{0}'.format(datax.shape))\n",
    "datay = np.vstack([trY, teY])\n",
    "print('datay.shape:{0}'.format(datay.shape))\n",
    "# dataX = trX and teX (10299, 3, 128)\n",
    "dataX = torch.Tensor(np.array(datax)).to(device)\n",
    "# dataY = trY and teY (10299,1)\n",
    "dataY = torch.Tensor(np.array(datay)).to(device)\n",
    "\n",
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "# trainYをone-hotにするためlongにして1次元配列に戻す　-> min~maxを0~5に直す\n",
    "trainY = trainY.view(-1).long() - 1\n",
    "print(trainY.shape)\n",
    "print(torch.min(trainY), torch.max(trainY))\n",
    "\n",
    "# one-hotにする -> 誤差を計算できるようにfloatに直す\n",
    "trainY = F.one_hot(trainY, num_classes=-1)\n",
    "trainY = trainY.float()\n",
    "print(trainY.shape)\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 70\n",
    "        self.lstm = nn.LSTM(input_size=3, hidden_size=self.hidden_size, num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(70, 6)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        _, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        h_out = self.relu(h_out)\n",
    "        h_out = self.linear(h_out)\n",
    "        y_hat = self.softmax(h_out)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "# print(summary(MyLSTM(), input_size=(7352, 128, 3), device=torch.device(device)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "  model.train()\n",
    "  y_hat = model(trainX)\n",
    "  loss = F.mse_loss(y_hat, trainY)\n",
    "  # loss = nn.CrossEntropyLoss()\n",
    "  # loss(y_hat, trainY)\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  return loss.item()\n",
    "\n",
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "  #data_predict = train_predict.data.numpy()\n",
    "  #dataY_plot = dataY.data.numpy()\n",
    "  # output tensor.argmax\n",
    "  \n",
    "  # data_predict = torch.argmax(train_predict, dim=-1)\n",
    "  # data_predict = F.one_hot(data_predict, num_classes=-1)\n",
    "  \n",
    "  # metric = ConfusionMatrix(num_classes=6)\n",
    "  # metric.attach(default_evaluator, 'cm')\n",
    "  # y_true = dataY.view(-1).int()\n",
    "  # y_pred = data_predict\n",
    "  # print(y_true.shape)\n",
    "  # print(y_pred.shape)\n",
    "\n",
    "  # state = default_evaluator.run([[y_pred, y_true]])\n",
    "  # print(state.metrics['cm'])\n",
    "\n",
    "loss = []\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epoch in range(500):\n",
    "    _loss = train(model, optimizer)\n",
    "    loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_step(engine, batch):\n",
    "#     return batch\n",
    "\n",
    "# default_evaluator = Engine(eval_step)\n",
    "\n",
    "# # create default optimizer for doctests\n",
    "\n",
    "# param_tensor = torch.zeros([1], requires_grad=True)\n",
    "# default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# # create default trainer for doctests\n",
    "# # as handlers could be attached to the trainer,\n",
    "# # each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "# def get_default_trainer():\n",
    "\n",
    "#     def train_step(engine, batch):\n",
    "#         return batch\n",
    "\n",
    "#     return Engine(train_step)\n",
    "\n",
    "# # create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# # manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 0.13914\n",
      "Epoch = 21, Loss = 0.13941\n",
      "Epoch = 41, Loss = 0.10847\n",
      "Epoch = 61, Loss = 0.10754\n",
      "Epoch = 81, Loss = 0.11516\n",
      "Epoch = 101, Loss = 0.12286\n",
      "Epoch = 121, Loss = 0.11097\n",
      "Epoch = 141, Loss = 0.10835\n",
      "Epoch = 161, Loss = 0.10251\n",
      "Epoch = 181, Loss = 0.10147\n",
      "Epoch = 201, Loss = 0.09864\n",
      "Epoch = 221, Loss = 0.07674\n",
      "Epoch = 241, Loss = 0.12249\n",
      "Epoch = 261, Loss = 0.10909\n",
      "Epoch = 281, Loss = 0.10713\n",
      "Epoch = 301, Loss = 0.10066\n",
      "Epoch = 321, Loss = 0.09406\n",
      "Epoch = 341, Loss = 0.08523\n",
      "Epoch = 361, Loss = 0.07816\n",
      "Epoch = 381, Loss = 0.07890\n",
      "Epoch = 401, Loss = 0.06939\n",
      "Epoch = 421, Loss = 0.08663\n",
      "Epoch = 441, Loss = 0.07831\n",
      "Epoch = 461, Loss = 0.07224\n",
      "Epoch = 481, Loss = 0.06974\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2947, 6])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
