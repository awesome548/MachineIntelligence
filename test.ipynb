{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "train_ax = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_x_train.txt\"))\n",
    "train_ay = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_y_train.txt\"))\n",
    "train_az = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_z_train.txt\"))\n",
    "\n",
    "train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "#test set\n",
    "test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "print(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7352\n",
    "test_size = 2947\n",
    "dim_size = 3\n",
    "sample_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape initial:(7352, 128, 3)\n",
      "trX.shape assigned:(7352, 128, 3)\n",
      "teX.shape initial:(2947, 128, 3)\n",
      "trX.shape assigned:(2947, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# trX = (7352, 128, 3) ... trainのX\n",
    "trX = np.ones((train_size, sample_size, dim_size), float)\n",
    "print('trX.shape initial:{0}'.format(trX.shape))\n",
    "for i in range(train_size):\n",
    "  temp1 = np.ones((dim_size, sample_size), float)\n",
    "  temp1[0,:] = train_ax[i,:]\n",
    "  temp1[1,:] = train_ay[i,:]\n",
    "  temp1[2,:] = train_az[i,:]\n",
    "  trX[i,:,:] = temp1.reshape(-1,3)\n",
    "print('trX.shape assigned:{0}'.format(trX.shape))\n",
    "\n",
    "# t(movement label) or s(subject label) or both ... trainのY (7352,1)\n",
    "trY = train_t.reshape(-1,1)\n",
    "\n",
    "# teX = (2947, 3, 128) ... testのX\n",
    "teX = np.ones((test_size, sample_size, dim_size), float)\n",
    "print('teX.shape initial:{0}'.format(teX.shape))\n",
    "for i in range(test_size):\n",
    "  temp2 = np.ones((dim_size, sample_size), float)\n",
    "  temp2[0,:] = test_ax[i,:]\n",
    "  temp2[1,:] = test_ay[i,:]\n",
    "  temp2[2,:] = test_az[i,:]\n",
    "  teX[i,:,:] = temp2.reshape(-1,3)\n",
    "print('trX.shape assigned:{0}'.format(teX.shape))\n",
    "\n",
    "# testのY 2947行1列\n",
    "teY = test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datax.shape:(10299, 128, 3)\n",
      "datay.shape:(10299, 1)\n",
      "torch.Size([7352])\n",
      "tensor(0, device='cuda:0') tensor(5, device='cuda:0')\n",
      "torch.Size([7352, 6])\n",
      "tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "(7352, 6)\n"
     ]
    }
   ],
   "source": [
    "datax = np.vstack([trX, teX])\n",
    "print('datax.shape:{0}'.format(datax.shape))\n",
    "datay = np.vstack([trY, teY])\n",
    "print('datay.shape:{0}'.format(datay.shape))\n",
    "# dataX = trX and teX (10299, 3, 128)\n",
    "dataX = torch.Tensor(np.array(datax)).to(device)\n",
    "# dataY = trY and teY (10299,1)\n",
    "dataY = torch.Tensor(np.array(datay)).to(device)\n",
    "\n",
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "# trainYをone-hotにするためlongにして1次元配列に戻す　-> min~maxを0~5に直す\n",
    "trainY = trainY.view(-1).long() - 1\n",
    "print(trainY.shape)\n",
    "print(torch.min(trainY), torch.max(trainY))\n",
    "\n",
    "# one-hotにする -> 誤差を計算できるようにfloatに直す\n",
    "trainY = F.one_hot(trainY, num_classes=-1)\n",
    "trainY = trainY.float()\n",
    "print(trainY.shape)\n",
    "print(trainY)\n",
    "trY = trainY.cpu().data.numpy()\n",
    "print(trY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全データ数: 7352\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet()\n",
    "print('全データ数:',len(dataset))  # \n",
    "#print('3番目のデータ:',dataset[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MyLSTM                                   [7352, 6]                 --\n",
      "├─LSTM: 1-1                              [7352, 128, 70]           21,000\n",
      "├─ReLU: 1-2                              [7352, 70]                --\n",
      "├─Linear: 1-3                            [7352, 6]                 426\n",
      "├─Softmax: 1-4                           [7352, 6]                 --\n",
      "==========================================================================================\n",
      "Total params: 21,426\n",
      "Trainable params: 21,426\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 19.77\n",
      "==========================================================================================\n",
      "Input size (MB): 11.29\n",
      "Forward/backward pass size (MB): 527.34\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 538.72\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 70\n",
    "        self.lstm = nn.LSTM(input_size=3, hidden_size=self.hidden_size, num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(70, 6)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        _, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        h_out = self.relu(h_out)\n",
    "        h_out = self.linear(h_out)\n",
    "        y_hat = self.softmax(h_out)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "print(summary(MyLSTM(), input_size=(7352, 128, 3), device=torch.device(device)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  #print(y_hat)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epoch in range(500):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 1.62958\n",
      "Epoch = 21, Loss = 1.54192\n",
      "Epoch = 41, Loss = 1.12143\n",
      "Epoch = 61, Loss = 1.10635\n",
      "Epoch = 81, Loss = 1.07080\n",
      "Epoch = 101, Loss = 1.11139\n",
      "Epoch = 121, Loss = 1.09288\n",
      "Epoch = 141, Loss = 1.11087\n",
      "Epoch = 161, Loss = 1.18195\n",
      "Epoch = 181, Loss = 1.05763\n",
      "Epoch = 201, Loss = 1.06416\n",
      "Epoch = 221, Loss = 1.13823\n",
      "Epoch = 241, Loss = 1.10223\n",
      "Epoch = 261, Loss = 1.09193\n",
      "Epoch = 281, Loss = 1.51463\n",
      "Epoch = 301, Loss = 1.39938\n",
      "Epoch = 321, Loss = 1.50908\n",
      "Epoch = 341, Loss = 1.59076\n",
      "Epoch = 361, Loss = 1.29763\n",
      "Epoch = 381, Loss = 1.24808\n",
      "Epoch = 401, Loss = 1.34997\n",
      "Epoch = 421, Loss = 1.27532\n",
      "Epoch = 441, Loss = 1.27053\n",
      "Epoch = 461, Loss = 1.59702\n",
      "Epoch = 481, Loss = 1.65407\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  data_predict = train_predict.cpu().data.numpy()\n",
    "  testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=-1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=-1)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=6)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.view(-1).int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2947, 6])\n",
      "torch.Size([2947])\n",
      "torch.Size([2947, 6])\n",
      "tensor([[  0,   0,   0,   0,   0,   0],\n",
      "        [253,  53, 149,  41,   0,   0],\n",
      "        [154, 132, 146,  39,   0,   0],\n",
      "        [159,  35, 192,  34,   0,   0],\n",
      "        [296,   2,  23, 169,   0,   1],\n",
      "        [477,  13,   3,  39,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be1730a4c75eedbbdd1e87842b276989c5900201d2db76eacd329e5d462cca92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
