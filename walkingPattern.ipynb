{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "train_ax = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_x_train.txt\"))\n",
    "train_ay = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_y_train.txt\"))\n",
    "train_az = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_z_train.txt\"))\n",
    "\n",
    "train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "#test set\n",
    "test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "print(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7352\n",
    "test_size = 2947\n",
    "dim_size = 3\n",
    "sample_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trX = (7352, 128, 3) ... trainのX\n",
    "trX = np.ones((train_size, sample_size, dim_size), float)\n",
    "print('trX.shape initial:{0}'.format(trX.shape))\n",
    "for i in range(train_size):\n",
    "  #temp1 = np.ones((dim_size, sample_size), float)\n",
    "  trX[i,:,0] = train_ax[i,:]\n",
    "  trX[i,:,1] = train_ay[i,:]\n",
    "  trX[i,:,2] = train_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(trX.shape))\n",
    "\n",
    "\n",
    "# t(movement label) or s(subject label) or both ... trainのY (7352,1)\n",
    "trY = train_t.reshape(-1,1)\n",
    "\n",
    "# teX = (2947, 3, 128) ... testのX\n",
    "teX = np.ones((test_size, sample_size, dim_size), float)\n",
    "print('teX.shape initial:{0}'.format(teX.shape))\n",
    "for i in range(test_size):\n",
    "  #temp2 = np.ones((dim_size, sample_size), float)\n",
    "  teX[i,:,0] = test_ax[i,:]\n",
    "  teX[i,:,1] = test_ay[i,:]\n",
    "  teX[i,:,2] = test_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(teX.shape))\n",
    "\n",
    "# testのY 2947行1列\n",
    "teY = test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_t[0], '.', label = \"train_ax\")\n",
    "plt.plot(trY[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = np.vstack([trX, teX])\n",
    "print('datax.shape:{0}'.format(datax.shape))\n",
    "datay = np.vstack([trY, teY])\n",
    "print('datay.shape:{0}'.format(datay.shape))\n",
    "# dataX = trX and teX (10299, 3, 128)\n",
    "dataX = torch.Tensor(np.array(datax)).to(device)\n",
    "# dataY = trY and teY (10299,1)\n",
    "dataY = torch.Tensor(np.array(datay)).to(device)\n",
    "\n",
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "# trainYをone-hotにするためlongにして1次元配列に戻す　-> min~maxを0~5に直す\n",
    "trainY = trainY.view(-1).long() - 1\n",
    "print(trainY.shape)\n",
    "print(torch.min(trainY), torch.max(trainY))\n",
    "\n",
    "# one-hotにする -> 誤差を計算できるようにfloatに直す\n",
    "trainY = F.one_hot(trainY, num_classes=-1)\n",
    "trainY = trainY.float()\n",
    "print(trainY.shape)\n",
    "print(trainY)\n",
    "trY = trainY.cpu().data.numpy()\n",
    "print(trY.shape)\n",
    "#print(trainX)\n",
    "testY = testY.view(-1).long() - 1\n",
    "# testY = F.one_hot(testY, num_classes=-1)\n",
    "# testY = testY.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet()\n",
    "print('全データ数:',len(dataset))  # \n",
    "#print('3番目のデータ:',dataset[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = 50\n",
    "        self.hidden_size_2 = 70\n",
    "        self.lstm_1 = nn.LSTM(input_size=3, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(70, 6)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "#print(summary(MyLSTM(), input_size=(7352, 128, 3), device=torch.device(device)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epoch in range(200):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=-1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=-1)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=6)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.view(-1).int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f1979eed7bd90e93f7098e88a58aab24ec26102a23b5ea93df2879eff80801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
