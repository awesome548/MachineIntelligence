{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchinfo import summary\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "path = \"./Dataset/\"\n",
    "mmscaler = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
    "\n",
    "#training set\n",
    "train_ax = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_x_train.txt\"))\n",
    "train_ay = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_y_train.txt\"))\n",
    "train_az = mmscaler.fit_transform(np.loadtxt(path + \"train/Inertial Signals/total_acc_z_train.txt\"))\n",
    "\n",
    "train_t = np.loadtxt(path + \"train/y_train.txt\").astype(int)\n",
    "train_s = np.loadtxt(path + \"train/subject_train.txt\").astype(int)\n",
    "\n",
    "#test set\n",
    "test_ax = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_x_test.txt\"))\n",
    "test_ay = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_y_test.txt\"))\n",
    "test_az = mmscaler.fit_transform(np.loadtxt(path + \"test/Inertial Signals/total_acc_z_test.txt\"))\n",
    "\n",
    "test_t = np.loadtxt(path + \"test/y_test.txt\").astype(int)\n",
    "test_s = np.loadtxt(path + \"test/subject_test.txt\").astype(int)\n",
    "\n",
    "print(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7352\n",
    "test_size = 2947\n",
    "dim_size = 3\n",
    "sample_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape initial:(7352, 128, 3)\n",
      "trX.shape assigned:(7352, 128, 3)\n",
      "teX.shape initial:(2947, 128, 3)\n",
      "trX.shape assigned:(2947, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# trX = (7352, 128, 3) ... trainのX\n",
    "trX = np.ones((train_size, sample_size, dim_size), float)\n",
    "print('trX.shape initial:{0}'.format(trX.shape))\n",
    "for i in range(train_size):\n",
    "  #temp1 = np.ones((dim_size, sample_size), float)\n",
    "  trX[i,:,0] = train_ax[i,:]\n",
    "  trX[i,:,1] = train_ay[i,:]\n",
    "  trX[i,:,2] = train_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(trX.shape))\n",
    "\n",
    "\n",
    "# t(movement label) or s(subject label) or both ... trainのY (7352,1)\n",
    "trY = train_t.reshape(-1,1)\n",
    "\n",
    "# teX = (2947, 3, 128) ... testのX\n",
    "teX = np.ones((test_size, sample_size, dim_size), float)\n",
    "print('teX.shape initial:{0}'.format(teX.shape))\n",
    "for i in range(test_size):\n",
    "  #temp2 = np.ones((dim_size, sample_size), float)\n",
    "  teX[i,:,0] = test_ax[i,:]\n",
    "  teX[i,:,1] = test_ay[i,:]\n",
    "  teX[i,:,2] = test_az[i,:]\n",
    "  \n",
    "print('trX.shape assigned:{0}'.format(teX.shape))\n",
    "\n",
    "# testのY 2947行1列\n",
    "teY = test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANaUlEQVR4nO3bf4zk9V3H8ecLTsBSKMfdccVujyvGRMEUWzaAkQi0lRZaAdE/MG2ttXghotYfpEJoGkRNLWokTVMvF2JstZRi7SVNVQLlRzBpT90tPyu/rgdYrtQ7KKlWIvS8t3/s9+KyzN7O7Mzc3H54PpLJfme+n519f26T502+M5uqQpK08h0y6QEkSaNh0CWpEQZdkhph0CWpEQZdkhqxalI/eO3atbVx48ZJ/XhJWpFmZ2efqap1vc5NLOgbN25kZmZmUj9eklakJE8uds5LLpLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUiL6CnuSJJA8kuTfJTI/z705yf7fmK0lOGf2okqT9WTXA2nOq6plFzj0OnFVVzyU5D9gCnD70dJKkvg0S9EVV1Vfm3d0GTI3ieSVJ/ev3GnoBtyaZTbJpibUfAP6x14kkm5LMJJnZvXv3IHNKkpbQ7yv0M6tqZ5LjgNuSPFxVdy9clOQc5oJ+Zq8nqaotzF2OYXp6upY5sySph75eoVfVzu7rLmArcNrCNUneCNwAXFhVz45ySEnS0pYMepIjkxy17xg4F3hwwZoNwBeA91bVo+MYVJK0f/1cclkPbE2yb/2NVXVLkssAqmoz8BFgDfDJbt2eqpoez8iSpF6WDHpV7QBe9rnyLuT7ji8FLh3taJKkQfiXopLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY3oK+hJnkjyQJJ7k8z0OP+jSb6a5IUkV4x+TEnSUlYNsPacqnpmkXPfAX4TuGjoiSRJyzKSSy5Vtauq/hX4/iieT5I0uH6DXsCtSWaTbBrnQJKk5en3ksuZVbUzyXHAbUkerqq7B/1h3X8GmwA2bNgw6LdLkvajr1foVbWz+7oL2AqctpwfVlVbqmq6qqbXrVu3nKeQJC1iyaAnOTLJUfuOgXOBB8c9mCRpMP1cclkPbE2yb/2NVXVLkssAqmpzktcCM8DRwN4kvwWcVFX/OZ6xJUkLLRn0qtoBnNLj8c3zjr8NTI12NEnSIPxLUUlqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqRF9BT/JEkgeS3Jtkpsf5JPl4ku1J7k/y5tGPKknan1UDrD2nqp5Z5Nx5wI90t9OBv+i+SivO7JPPsW3Hs5xx4hpOPWH1pMeR+jZI0PfnQuDTVVXAtiTHJDm+qp4e0fNLB8Tsk8/x7hu28eKevRy26hA+c+kZRl0rRr/X0Au4Nclskk09zr8O+Oa8+091j71Ekk1JZpLM7N69e/BppTHbtuNZXtyzl70F39+zl207np30SFLf+g36mVX1ZuYurVye5KeX88OqaktVTVfV9Lp165bzFNJYnXHiGg5bdQiHBn5g1SGcceKaSY8k9a2vSy5VtbP7uivJVuA04O55S3YCr593f6p7TFpRTj1hNZ+59AyvoWtFWjLoSY4EDqmq/+qOzwWuXbDsi8CvJ7mJuTdDv+v1c61Up56w2pBrRernFfp6YGuSfetvrKpbklwGUFWbgX8Azge2A88D7x/PuJKkxSwZ9KraAZzS4/HN844LuHy0o0mSBuFfikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDWi76AnOTTJPUm+1OPcCUluT3J/kruSTI12TEnSUgZ5hf5B4KFFzv0p8OmqeiNwLfDRYQeTJA2mr6B3r7jfCdywyJKTgDu64zuBC4cfTZI0iH5foV8PfAjYu8j5+4CLu+OfA45Ksma40SRJg1gy6EneBeyqqtn9LLsCOCvJPcBZwE7gf3s816YkM0lmdu/evdyZJUk9pKr2vyD5KPBeYA9wBHA08IWqes8i618NPFxV+31jdHp6umZmZpY1tCS9UiWZrarpXueWfIVeVVdV1VRVbQQuAe5YGPMka5Pse66rgL8ccmZJ0oCW/Tn0JNcmuaC7ezbwSJJHgfXAH41gNknSAJa85DIuXnKRpMENdclFkrQyGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RG9B30JIcmuSfJl3qc25Dkzu78/UnOH+2YkqSlDPIK/YPAQ4uc+zBwc1W9CbgE+OSwg0mSBtNX0JNMAe8EblhkSQFHd8evAb41/GiSpEGs6nPd9cCHgKMWOX8NcGuS3wCOBN7Wa1GSTcAmgA0bNgwypyRpCUu+Qk/yLmBXVc3uZ9kvAn9VVVPA+cBfJ3nZc1fVlqqarqrpdevWLXtoSdLL9XPJ5aeAC5I8AdwEvCXJ3yxY8wHgZoCq+ipwBLB2hHNKkpawZNCr6qqqmqqqjcy94XlHVb1nwbJ/B94KkOTHmAv67hHPKknaj2V/Dj3JtUku6O7+LvCrSe4DPgv8clXVKAaUJPWn3zdFAaiqu4C7uuOPzHv835i7NCNJmhD/UlSSGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRqarJ/OBkN/DkRH74cNYCz0x6iAPMPbfvlbZfWLl7PqGq1vU6MbGgr1RJZqpqetJzHEjuuX2vtP1Cm3v2koskNcKgS1IjDPrgtkx6gAlwz+17pe0XGtyz19AlqRG+QpekRhh0SWqEQe8hybFJbkvyWPd19SLr3teteSzJ+3qc/2KSB8c/8fCG2XOSVyX5+yQPJ/l6kj8+sNP3L8k7kjySZHuSK3ucPzzJ57rz/5xk47xzV3WPP5Lk7Qd08CEsd89JfibJbJIHuq9vOeDDL9Mwv+fu/IYk30tyxQEbehSqytuCG3AdcGV3fCXwsR5rjgV2dF9Xd8er552/GLgReHDS+xn3noFXAed0aw4D/gk4b9J76jH/ocA3gBO7Oe8DTlqw5teAzd3xJcDnuuOTuvWHA2/onufQSe9pzHt+E/BD3fGPAzsnvZ9x73ne+c8DfwtcMen9DHLzFXpvFwKf6o4/BVzUY83bgduq6jtV9RxwG/AOgCSvBn4H+MPxjzoyy95zVT1fVXcCVNWLwNeAqfGPPLDTgO1VtaOb8ybm9j3f/H+HzwNvTZLu8Zuq6oWqehzY3j3fwW7Ze66qe6rqW93jXwd+MMnhB2Tq4QzzeybJRcDjzO15RTHova2vqqe7428D63useR3wzXn3n+oeA/gD4M+A58c24egNu2cAkhwD/Cxw+xhmHNaS889fU1V7gO8Ca/r83oPRMHue7+eBr1XVC2Oac5SWvefuxdjvAb9/AOYcuVWTHmBSknwZeG2PU1fPv1NVlaTvz3Ym+Qngh6vqtxdel5u0ce153vOvAj4LfLyqdixvSh1skpwMfAw4d9KzHADXAH9eVd/rXrCvKK/YoFfV2xY7l+Q/khxfVU8nOR7Y1WPZTuDsefengLuAnwSmkzzB3L/vcUnuqqqzmbAx7nmfLcBjVXX98NOOxU7g9fPuT3WP9VrzVPcf1GuAZ/v83oPRMHsmyRSwFfilqvrG+McdiWH2fDrwC0muA44B9ib5n6r6xNinHoVJX8Q/GG/An/DSNwiv67HmWOaus63ubo8Dxy5Ys5GV86boUHtm7v2CvwMOmfRe9rPHVcy9kfsG/v/NspMXrLmcl75ZdnN3fDIvfVN0ByvjTdFh9nxMt/7iSe/jQO15wZprWGFvik58gIPxxtz1w9uBx4Avz4vWNHDDvHW/wtybY9uB9/d4npUU9GXvmblXQAU8BNzb3S6d9J4W2ef5wKPMfQri6u6xa4ELuuMjmPt0w3bgX4AT533v1d33PcJB+CmeUe8Z+DDw3/N+p/cCx016P+P+Pc97jhUXdP/0X5Ia4adcJKkRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakR/wfB4AjyKlT01AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_t[0], '.', label = \"train_ax\")\n",
    "plt.plot(trY[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datax.shape:(10299, 128, 3)\n",
      "datay.shape:(10299, 1)\n",
      "torch.Size([7352])\n",
      "tensor(0, device='cuda:0') tensor(5, device='cuda:0')\n",
      "torch.Size([7352, 6])\n",
      "tensor([[0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "(7352, 6)\n"
     ]
    }
   ],
   "source": [
    "datax = np.vstack([trX, teX])\n",
    "print('datax.shape:{0}'.format(datax.shape))\n",
    "datay = np.vstack([trY, teY])\n",
    "print('datay.shape:{0}'.format(datay.shape))\n",
    "# dataX = trX and teX (10299, 3, 128)\n",
    "dataX = torch.Tensor(np.array(datax)).to(device)\n",
    "# dataY = trY and teY (10299,1)\n",
    "dataY = torch.Tensor(np.array(datay)).to(device)\n",
    "\n",
    "trainX = torch.Tensor(np.array(trX)).to(device)\n",
    "trainY = torch.Tensor(np.array(trY)).to(device)\n",
    "\n",
    "testX = torch.Tensor(np.array(teX)).to(device)\n",
    "testY = torch.Tensor(np.array(teY)).to(device)\n",
    "\n",
    "# trainYをone-hotにするためlongにして1次元配列に戻す　-> min~maxを0~5に直す\n",
    "trainY = trainY.view(-1).long() - 1\n",
    "print(trainY.shape)\n",
    "print(torch.min(trainY), torch.max(trainY))\n",
    "\n",
    "# one-hotにする -> 誤差を計算できるようにfloatに直す\n",
    "trainY = F.one_hot(trainY, num_classes=-1)\n",
    "trainY = trainY.float()\n",
    "print(trainY.shape)\n",
    "print(trainY)\n",
    "trY = trainY.cpu().data.numpy()\n",
    "print(trY.shape)\n",
    "#print(trainX)\n",
    "testY = testY.view(-1).long() - 1\n",
    "# testY = F.one_hot(testY, num_classes=-1)\n",
    "# testY = testY.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2947, 128, 3])\n",
      "tensor([4, 4, 4,  ..., 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.X = trX.astype(np.float32) # 入力\n",
    "        self.t = trY # 出力\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) # データ数(10)を返す\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index番目の入出力ペアを返す\n",
    "        return self.X[index], self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全データ数: 7352\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet()\n",
    "print('全データ数:',len(dataset))  # \n",
    "#print('3番目のデータ:',dataset[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さっき作ったDataSetクラスのインスタンスを作成\n",
    "dataset = DataSet()\n",
    "# datasetをDataLoaderの引数とすることでミニバッチを作成．\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, \\\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size_1 = 50\n",
    "        self.hidden_size_2 = 70\n",
    "        self.lstm_1 = nn.LSTM(input_size=3, hidden_size=self.hidden_size_1, num_layers=1, batch_first=True) \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2, num_layers=1, batch_first=True) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(70, 6)\n",
    "        #self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        c_0 = torch.zeros(1, x.size(0), self.hidden_size_1).to(device)\n",
    "        h_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        c_1 = torch.zeros(1, x.size(0), self.hidden_size_2).to(device)\n",
    "        out, (h_out, c_out) = self.lstm_1(x, (h_0, c_0))\n",
    "        _, (h_out, _) = self.lstm_2(out, (h_1, c_1))\n",
    "        h_out = h_out.view(-1, self.hidden_size_2)\n",
    "        h_out = self.relu(h_out)\n",
    "        y_hat = self.linear(h_out)\n",
    "        #y_hat = self.softmax(h_out)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "#print(summary(MyLSTM(), input_size=(7352, 128, 3), device=torch.device(device)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, t):\n",
    "  model.train()\n",
    "  y_hat = model(X)\n",
    "  # print(y_hat.shape)\n",
    "  # loss = F.mse_loss(y_hat, trainY)\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  output = loss(y_hat, t)\n",
    "  optimizer.zero_grad()\n",
    "  output.backward()\n",
    "  optimizer.step()\n",
    "  return output.item()\n",
    "\n",
    "loss = []\n",
    "\n",
    "def main():\n",
    "  model = MyLSTM()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epoch in range(200):\n",
    "    for X, t in dataloader:\n",
    "      _loss = train(model, optimizer, X.to(device), t.to(device))\n",
    "      loss.append(_loss)\n",
    "    if epoch % 20 == 0:\n",
    "      print(f\"Epoch = {epoch+1}, Loss = {_loss:.5f}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "# default_model = nn.Sequential(OrderedDict([\n",
    "#     ('base', nn.Linear(4, 2)),\n",
    "#     ('fc', nn.Linear(2, 1))\n",
    "# ]))\n",
    "\n",
    "# manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Loss = 1.79026\n",
      "Epoch = 21, Loss = 1.07784\n",
      "Epoch = 41, Loss = 0.98921\n",
      "Epoch = 61, Loss = 1.35090\n",
      "Epoch = 81, Loss = 0.59757\n",
      "Epoch = 101, Loss = 0.48095\n",
      "Epoch = 121, Loss = 0.16395\n",
      "Epoch = 141, Loss = 0.32191\n",
      "Epoch = 161, Loss = 0.15064\n",
      "Epoch = 181, Loss = 0.09182\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "  model.eval()\n",
    "  train_predict = model(testX)\n",
    "  print(train_predict.shape)\n",
    "\n",
    "  #data_predict = train_predict.cpu().data.numpy()\n",
    "  #testY_plot = testY.cpu().data.numpy()\n",
    "\n",
    "  \n",
    "  data_predict = torch.argmax(train_predict, dim=-1)\n",
    "  data_predict = F.one_hot(data_predict, num_classes=-1)\n",
    "  \n",
    "  metric = ConfusionMatrix(num_classes=6)\n",
    "  metric.attach(default_evaluator, 'cm')\n",
    "  y_true = testY.view(-1).int()\n",
    "  y_pred = data_predict\n",
    "  print(y_true.shape)\n",
    "  print(y_pred.shape)\n",
    "\n",
    "  state = default_evaluator.run([[y_pred, y_true]])\n",
    "  print(state.metrics['cm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2947, 6])\n",
      "torch.Size([2947])\n",
      "torch.Size([2947, 6])\n",
      "tensor([[447,  49,   0,   0,   0,   0],\n",
      "        [ 31, 404,  36,   0,   0,   0],\n",
      "        [  2,  53, 365,   0,   0,   0],\n",
      "        [  0,  23,   0, 409,  59,   0],\n",
      "        [ 13,   0,   0, 118, 401,   0],\n",
      "        [  0,   2,   0,   0,   0, 535]])\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akota\\Desktop\\program\\歩行検知LSTM\\MachineIntelligence\\test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/%E6%AD%A9%E8%A1%8C%E6%A4%9C%E7%9F%A5LSTM/MachineIntelligence/test.ipynb#ch0000000?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(loss, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, label \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akota/Desktop/program/%E6%AD%A9%E8%A1%8C%E6%A4%9C%E7%9F%A5LSTM/MachineIntelligence/test.ipynb#ch0000000?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(loss, '.', label = \"test_error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "80f1979eed7bd90e93f7098e88a58aab24ec26102a23b5ea93df2879eff80801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
